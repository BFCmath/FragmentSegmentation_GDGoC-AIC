{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c91ac38",
   "metadata": {
    "papermill": {
     "duration": 0.007172,
     "end_time": "2025-03-11T17:08:01.129543",
     "exception": false,
     "start_time": "2025-03-11T17:08:01.122371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b283ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:08:01.143450Z",
     "iopub.status.busy": "2025-03-11T17:08:01.143127Z",
     "iopub.status.idle": "2025-03-11T17:11:22.096196Z",
     "shell.execute_reply": "2025-03-11T17:11:22.095079Z"
    },
    "papermill": {
     "duration": 200.961793,
     "end_time": "2025-03-11T17:11:22.097929",
     "exception": false,
     "start_time": "2025-03-11T17:08:01.136136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d56a4709060>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/segmentation-models-pytorch/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d56a4709390>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/segmentation-models-pytorch/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d56a4709630>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/segmentation-models-pytorch/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d56a47097e0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/segmentation-models-pytorch/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d56a4709990>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/segmentation-models-pytorch/\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement segmentation-models-pytorch (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for segmentation-models-pytorch\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install segmentation-models-pytorch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69bd805e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:11:22.112213Z",
     "iopub.status.busy": "2025-03-11T17:11:22.111917Z",
     "iopub.status.idle": "2025-03-11T17:12:05.890647Z",
     "shell.execute_reply": "2025-03-11T17:12:05.889843Z"
    },
    "papermill": {
     "duration": 43.787515,
     "end_time": "2025-03-11T17:12:05.892363",
     "exception": false,
     "start_time": "2025-03-11T17:11:22.104848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/check_version.py:51: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471b22f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:05.905791Z",
     "iopub.status.busy": "2025-03-11T17:12:05.905342Z",
     "iopub.status.idle": "2025-03-11T17:12:05.910809Z",
     "shell.execute_reply": "2025-03-11T17:12:05.909926Z"
    },
    "papermill": {
     "duration": 0.013512,
     "end_time": "2025-03-11T17:12:05.912092",
     "exception": false,
     "start_time": "2025-03-11T17:12:05.898580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install segmentation_models_pytorch: pip install segmentation-models-pytorch\n"
     ]
    }
   ],
   "source": [
    "# Try importing segmentation_models_pytorch\n",
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "except ImportError:\n",
    "    print(\"Please install segmentation_models_pytorch: pip install segmentation-models-pytorch\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d95aec",
   "metadata": {
    "papermill": {
     "duration": 0.0063,
     "end_time": "2025-03-11T17:12:05.924646",
     "exception": false,
     "start_time": "2025-03-11T17:12:05.918346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001bf7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T17:12:05.937766Z",
     "iopub.status.busy": "2025-03-11T17:12:05.937504Z",
     "iopub.status.idle": "2025-03-11T17:12:06.006415Z",
     "shell.execute_reply": "2025-03-11T17:12:06.005550Z"
    },
    "papermill": {
     "duration": 0.077358,
     "end_time": "2025-03-11T17:12:06.007886",
     "exception": false,
     "start_time": "2025-03-11T17:12:05.930528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME_VERSION = \"unet-v2.1\"    \n",
    "# Parameters\n",
    "TRAIN_IMAGE_DIR = '/kaggle/input/gd-go-c-hcmus-aic-fragment-segmentation-track/train/images'\n",
    "TRAIN_MASK_DIR = '/kaggle/input/gd-go-c-hcmus-aic-fragment-segmentation-track/train/masks'\n",
    "VAL_IMAGE_DIR = '/kaggle/input/gd-go-c-hcmus-aic-fragment-segmentation-track/val/images'\n",
    "\n",
    "OUTPUT_DIR = f'/kaggle/working/{NAME_VERSION}'\n",
    "\n",
    "TARGET_SIZE = 512  # Higher resolution for better segmentation\n",
    "BATCH_SIZE = 4     # Smaller batch size for higher resolution\n",
    "NUM_EPOCHS = 50    # More epochs for better convergence\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 1e-5  # L2 regularization\n",
    "USE_AMP = False     # Use mixed precision for faster training\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e8998",
   "metadata": {
    "execution": {},
    "papermill": {
     "duration": 2.009284,
     "end_time": "2025-03-11T17:12:08.023880",
     "exception": false,
     "start_time": "2025-03-11T17:12:06.014596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba2138",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if files exist in directories\n",
    "if not os.path.exists(TRAIN_IMAGE_DIR):\n",
    "    raise FileNotFoundError(f\"Training image directory not found: {TRAIN_IMAGE_DIR}\")\n",
    "if not os.path.exists(TRAIN_MASK_DIR):\n",
    "    raise FileNotFoundError(f\"Training mask directory not found: {TRAIN_MASK_DIR}\")\n",
    "if not os.path.exists(VAL_IMAGE_DIR):\n",
    "    raise FileNotFoundError(f\"Validation image directory not found: {VAL_IMAGE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53902c95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a174b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98646137",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c2847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset class for training\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir=None, transform=None, image_list=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get list of image files\n",
    "        if image_list is not None:\n",
    "            self.images = image_list\n",
    "        else:\n",
    "            self.images = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        \n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        \n",
    "        if self.mask_dir:  # Training or validation with masks\n",
    "            mask_name = os.path.splitext(img_name)[0] + '.png'\n",
    "            mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "            \n",
    "            # Handle mask loading errors gracefully\n",
    "            try:\n",
    "                mask = np.array(Image.open(mask_path).convert(\"L\"))  # Grayscale\n",
    "                # Ensure mask is binary (0 or 1)\n",
    "                mask = (mask > 0).astype(np.float32)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading mask {mask_path}: {e}\")\n",
    "                # Create an empty mask if there's an error\n",
    "                mask = np.zeros(image.shape[:2], dtype=np.float32)\n",
    "            \n",
    "            if self.transform:\n",
    "                augmentations = self.transform(image=image, mask=mask)\n",
    "                image = augmentations[\"image\"]\n",
    "                mask = augmentations[\"mask\"]\n",
    "            return image, mask\n",
    "        else:  # Test set, no masks\n",
    "            if self.transform:\n",
    "                augmentations = self.transform(image=image)\n",
    "                image = augmentations[\"image\"]\n",
    "            return image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00fdad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transformations with specific target size for blast fragments\n",
    "def get_transforms(train=True, target_size=512):  # Increased size for better detail\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.Resize(height=target_size, width=target_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(p=0.5),\n",
    "            A.GaussianBlur(p=0.3),\n",
    "            A.GaussNoise(p=0.2),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(height=target_size, width=target_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0888ef6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15181675",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RLE encoding function from the competition description\n",
    "def mask_to_rle(mask):\n",
    "    \"\"\"\n",
    "    Convert a binary mask to run-length encoding (RLE)\n",
    "    \"\"\"\n",
    "    # Flatten mask\n",
    "    pixels = mask.flatten()\n",
    "    # Compress the mask with RLE\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    # Convert to string\n",
    "    rle = ' '.join(str(x) for x in runs)\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3517837",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RLE decoding function for the competition\n",
    "def rle_to_mask(rle, shape):\n",
    "    \"\"\"\n",
    "    Convert RLE to mask\n",
    "    \"\"\"\n",
    "    if rle == '' or rle is None:\n",
    "        return np.zeros(shape, dtype=np.uint8)\n",
    "    \n",
    "    s = rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1  # RLE starts from 1, convert to 0-based indexing\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606207a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IoU (Jaccard Index) for evaluation as per competition metric\n",
    "def iou_score(pred, target, smooth=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505ff85",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display predictions\n",
    "def display_predictions(model, dataset, device, num_samples=3, save_path='predictions.png'):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    # Sample indices randomly\n",
    "    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, mask = dataset[idx]\n",
    "        \n",
    "        image_tensor = image.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor)\n",
    "            pred_mask = torch.sigmoid(output) > 0.5\n",
    "        \n",
    "        # Convert tensors to numpy for display\n",
    "        image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "        mask_np = mask.cpu().numpy()\n",
    "        pred_mask_np = pred_mask.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Denormalize image\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image_np = std * image_np + mean\n",
    "        image_np = np.clip(image_np, 0, 1)\n",
    "        \n",
    "        # Display\n",
    "        axes[i, 0].imshow(image_np)\n",
    "        axes[i, 0].set_title(\"Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(mask_np, cmap='gray')\n",
    "        axes[i, 1].set_title(\"Ground Truth\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(pred_mask_np, cmap='gray')\n",
    "        axes[i, 2].set_title(\"Prediction\")\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee8a5c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save training history plot and metrics\n",
    "def save_training_history(train_losses, val_losses, train_ious, val_ious, save_dir):\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    history = {\n",
    "        'epoch': list(range(1, len(train_losses) + 1)),\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "        'train_iou': train_ious,\n",
    "        'val_iou': val_ious\n",
    "    }\n",
    "    pd.DataFrame(history).to_csv(os.path.join(save_dir, 'training_history.csv'), index=False)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['epoch'], train_losses, 'b-', label='Training Loss')\n",
    "    plt.plot(history['epoch'], val_losses, 'r-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['epoch'], train_ious, 'b-', label='Training IoU')\n",
    "    plt.plot(history['epoch'], val_ious, 'r-', label='Validation IoU')\n",
    "    plt.title('Training and Validation IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'training_history.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c635d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train and val helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52256c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training function with mixed precision\n",
    "def train_epoch(model, loader, optimizer, criterion, device, scaler=None):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    iou_scores = []\n",
    "    \n",
    "    for images, masks in tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.float().to(device).unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        # Use mixed precision if scaler is provided\n",
    "        if scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "            # Scale gradients and optimize\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Calculate IoU score for this batch\n",
    "        with torch.no_grad():\n",
    "            pred_masks = torch.sigmoid(outputs)\n",
    "            iou = iou_score(pred_masks, masks)\n",
    "            iou_scores.append(iou.item())\n",
    "    \n",
    "    return epoch_loss / len(loader), np.mean(iou_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac63062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def valid_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    iou_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.float().to(device).unsqueeze(1)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            pred_masks = torch.sigmoid(outputs)\n",
    "            iou = iou_score(pred_masks, masks)\n",
    "            iou_scores.append(iou.item())\n",
    "    \n",
    "    return epoch_loss / len(loader), np.mean(iou_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fb0c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da870e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction and RLE encoding for competition submission\n",
    "def predict_and_encode(model, loader, device, target_size=512):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, img_names in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            pred_masks = (torch.sigmoid(outputs) > 0.5).float().cpu().numpy()\n",
    "            \n",
    "            for pred_mask, img_name in zip(pred_masks, img_names):\n",
    "                pred_mask = pred_mask.squeeze()  # Remove channel dimension\n",
    "                # Convert to RLE format\n",
    "                rle = mask_to_rle(pred_mask)\n",
    "                image_id = os.path.splitext(img_name)[0]\n",
    "                predictions.append({'id': image_id, 'rle': rle})\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b7551e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e1616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all images\n",
    "all_images = [f for f in os.listdir(TRAIN_IMAGE_DIR) if f.endswith('.jpg')]\n",
    "print(f\"Found {len(all_images)} images in training directory\")\n",
    "\n",
    "# Verify mask files exist for training images\n",
    "valid_images = []\n",
    "for img_file in all_images:\n",
    "    mask_file = os.path.splitext(img_file)[0] + '.png'\n",
    "    if os.path.exists(os.path.join(TRAIN_MASK_DIR, mask_file)):\n",
    "        valid_images.append(img_file)\n",
    "\n",
    "if len(valid_images) < len(all_images):\n",
    "    print(f\"Warning: Only {len(valid_images)} of {len(all_images)} images have corresponding masks\")\n",
    "\n",
    "# Split data into train and validation\n",
    "train_images, valid_images = train_test_split(\n",
    "    valid_images, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training images: {len(train_images)}\")\n",
    "print(f\"Validation images: {len(valid_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83175fc7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13122a79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "train_transform = get_transforms(train=True, target_size=TARGET_SIZE)\n",
    "valid_transform = get_transforms(train=False, target_size=TARGET_SIZE)\n",
    "\n",
    "# Data loaders with appropriate number of workers\n",
    "num_workers = min(8, os.cpu_count() or 1)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SegmentationDataset(\n",
    "    image_dir=TRAIN_IMAGE_DIR,\n",
    "    mask_dir=TRAIN_MASK_DIR,\n",
    "    transform=train_transform,\n",
    "    image_list=train_images\n",
    ")\n",
    "\n",
    "valid_dataset = SegmentationDataset(\n",
    "    image_dir=TRAIN_IMAGE_DIR,\n",
    "    mask_dir=TRAIN_MASK_DIR,\n",
    "    transform=valid_transform,\n",
    "    image_list=valid_images\n",
    ")\n",
    "\n",
    "test_dataset = SegmentationDataset(\n",
    "    image_dir=VAL_IMAGE_DIR,\n",
    "    mask_dir=None,\n",
    "    transform=valid_transform\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680079e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b7485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model - try a different architecture\n",
    "model = smp.UnetPlusPlus(  # UNet++ often performs better for medical-like segmentation\n",
    "    encoder_name=\"efficientnet-b3\",  # Higher capacity encoder\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5257ca1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loss/Optimizer/Scheduler/Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d6570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function - Combined BCE and Dice loss for better boundary detection\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=0.5):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.weight = weight  # Weight for BCE vs Dice\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        # BCE Loss\n",
    "        bce_loss = self.bce(pred, target)\n",
    "        \n",
    "        # Dice Loss\n",
    "        pred_sigmoid = torch.sigmoid(pred)\n",
    "        intersection = (pred_sigmoid * target).sum()\n",
    "        dice_loss = 1 - (2. * intersection + 1) / (pred_sigmoid.sum() + target.sum() + 1)\n",
    "        \n",
    "        # Combine losses\n",
    "        return self.weight * bce_loss + (1 - self.weight) * dice_loss\n",
    "\n",
    "criterion = BCEDiceLoss(weight=0.7)\n",
    "\n",
    "# Initialize mixed precision scaler\n",
    "scaler = GradScaler() if USE_AMP and DEVICE.type == 'cuda' else None\n",
    "\n",
    "\n",
    "# Optimizer with weight decay for regularization\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Learning rate scheduler with cosine annealing\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=5,  # Restart every 5 epochs\n",
    "    T_mult=1, \n",
    "    eta_min=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d961142",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Traing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c78b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_iou = -1\n",
    "model_save_path = os.path.join(OUTPUT_DIR, \"best_model.pth\")\n",
    "\n",
    "# For tracking metrics\n",
    "train_losses, val_losses = [], []\n",
    "train_ious, val_ious = [], []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_iou = train_epoch(model, train_loader, optimizer, criterion, DEVICE, scaler)\n",
    "    \n",
    "    # Validate\n",
    "    valid_loss, valid_iou = valid_epoch(model, valid_loader, criterion, DEVICE)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Track metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(valid_loss)\n",
    "    train_ious.append(train_iou)\n",
    "    val_ious.append(valid_iou)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}\")\n",
    "    print(f\"Valid Loss: {valid_loss:.4f}, Valid IoU: {valid_iou:.4f}\")\n",
    "    print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if valid_iou > best_iou:\n",
    "        best_iou = valid_iou\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_iou': best_iou,\n",
    "        }, model_save_path)\n",
    "        print(f\"Saved best model to {model_save_path}!\")\n",
    "\n",
    "# Calculate training time\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best validation IoU: {best_iou:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdb1f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e38ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save training history\n",
    "save_training_history(train_losses, val_losses, train_ious, val_ious, OUTPUT_DIR)\n",
    "\n",
    "# Load best model for evaluation and prediction\n",
    "checkpoint = torch.load(model_save_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Validate with best model\n",
    "valid_loss, valid_iou = valid_epoch(model, valid_loader, criterion, DEVICE)\n",
    "print(f\"Best model - Valid Loss: {valid_loss:.4f}, Valid IoU: {valid_iou:.4f}\")\n",
    "\n",
    "# Save visualizations of predictions\n",
    "display_predictions(\n",
    "    model, \n",
    "    valid_dataset, \n",
    "    DEVICE, \n",
    "    num_samples=5, \n",
    "    save_path=os.path.join(OUTPUT_DIR, 'predictions.png')\n",
    ")\n",
    "print(f\"Predictions visualization saved to '{os.path.join(OUTPUT_DIR, 'predictions.png')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356f5ac",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86226e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T19:15:25.90899Z",
     "iopub.status.busy": "2025-03-10T19:15:25.908767Z",
     "iopub.status.idle": "2025-03-10T19:15:37.043643Z",
     "shell.execute_reply": "2025-03-10T19:15:37.042774Z",
     "shell.execute_reply.started": "2025-03-10T19:15:25.908971Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate predictions for test set and save in RLE format\n",
    "test_predictions = predict_and_encode(model, test_loader, DEVICE, target_size=TARGET_SIZE)\n",
    "submission_df = pd.DataFrame(test_predictions)\n",
    "submission_path = os.path.join(OUTPUT_DIR, 'submission.csv')\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved to '{submission_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11322077,
     "sourceId": 95050,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 249.788349,
   "end_time": "2025-03-11T17:12:08.035731",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-11T17:07:58.247382",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
